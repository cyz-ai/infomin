{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import USCensus, UCICrime\n",
    "from tasks.fairness.experiment import train, test\n",
    "from tasks.fairness.model import FairNet\n",
    "import utils_os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([20000, 16]) torch.Size([20000, 1])\n",
      "test torch.Size([2500, 16]) torch.Size([2500, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y, A = UCICrime.read_dataset(name='adult')\n",
    "X = torch.Tensor(X).to(device)                     # input data\n",
    "Y = torch.Tensor(Y).to(device)                     # target to predict\n",
    "A = torch.Tensor(A).to(device)                     # sensitive attribute\n",
    "assert X[0, -1] == A[0, -1]                        # the last index of x is also the sensitive attr \n",
    "assert X[0, -2] != A[0, -1]\n",
    "dim = 20\n",
    "n, d = X.size()\n",
    "n, K = Y.size()\n",
    "\n",
    "N = 20000\n",
    "x, y, a = X[0:N,:], Y[0:N, :], A[0:N, :]\n",
    "x = (x - x.mean(dim=0, keepdim=True))/x.std(dim=0, keepdim=True)\n",
    "x_test, y_test, a_test = X[N:N+2500,:], Y[N:N+2500, :], A[N:N+2500, :]\n",
    "x_test = (x_test - x_test.mean(dim=0, keepdim=True))/x_test.std(dim=0, keepdim=True)\n",
    "print('train', x.size(), y.size())\n",
    "print('test', x_test.size(), y_test.size())\n",
    "\n",
    "DATASET = 'UCIAdult'\n",
    "dim_z = 4*dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/A\n",
    "\n",
    "Plain model that has no constraint on I(Z; T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -9.857749938964844 loss val= -1.1813234090805054 adv_loss= tensor([0.], device='cuda:0') time= 0.0008447170257568359\n",
      "t= 50 loss= -9.96342658996582 loss val= -9.973118782043457 adv_loss= tensor([0.], device='cuda:0') time= 0.0008435249328613281\n",
      "t= 100 loss= -9.957209587097168 loss val= -9.987390518188477 adv_loss= tensor([0.], device='cuda:0') time= 0.0008449554443359375\n",
      "t= 150 loss= -9.970044136047363 loss val= -9.990811347961426 adv_loss= tensor([0.], device='cuda:0') time= 0.0008385181427001953\n",
      "t= 200 loss= -9.93735408782959 loss val= -9.993398666381836 adv_loss= tensor([0.], device='cuda:0') time= 0.0008389949798583984\n",
      "t= 250 loss= -9.951817512512207 loss val= -9.972981452941895 adv_loss= tensor([0.], device='cuda:0') time= 0.0008325576782226562\n",
      "t= 300 loss= -9.93704605102539 loss val= -9.986382484436035 adv_loss= tensor([0.], device='cuda:0') time= 0.0008449554443359375\n",
      "t= 350 loss= -9.964373588562012 loss val= -9.990212440490723 adv_loss= tensor([0.], device='cuda:0') time= 0.0008208751678466797\n",
      "t= 400 loss= -9.967499732971191 loss val= -9.988290786743164 adv_loss= tensor([0.], device='cuda:0') time= 0.0008347034454345703\n",
      "t= 450 loss= -9.976738929748535 loss val= -9.994783401489258 adv_loss= tensor([0.], device='cuda:0') time= 0.0008451938629150391\n",
      "best val loss= 9.996098518371582 t= 499 best_t 441 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9992501735687256\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.057064902037382126 loss val= -0.007814810611307621 -0.007814810611307621\n",
      "finished: t= 100 loss= -0.9650087952613831 loss val= -0.9422951340675354 -0.9686683416366577\n",
      "finished: t= 200 loss= -0.9517203569412231 loss val= -0.9741389751434326 -0.9763163328170776\n",
      "finished: t= 300 loss= -0.9792365431785583 loss val= -0.9808364510536194 -0.9813591837882996\n",
      "finished: t= 400 loss= -0.9812453985214233 loss val= -0.9842318296432495 -0.9842318296432495\n",
      "finished: t= 500 loss= -0.973889946937561 loss val= -0.98493492603302 -0.9852873682975769\n",
      "finished: t= 600 loss= -0.9763478636741638 loss val= -0.9848384857177734 -0.9864734411239624\n",
      "finished: t= 700 loss= -0.9799091815948486 loss val= -0.9847096800804138 -0.9868872761726379\n",
      "finished: t= 800 loss= -0.9864776730537415 loss val= -0.9868932962417603 -0.9881040453910828\n",
      "finished: t= 900 loss= -0.988853394985199 loss val= -0.9806995391845703 -0.9884318709373474\n",
      "[val] rho*(Z;T) = 0.9891101121902466\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9980000257492065\n",
      "[test] rho*(Z;T)= 0.9869883060455322\n"
     ]
    }
   ],
   "source": [
    "estimator = 'NONE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 10\n",
    "        self.lr = 1e-3\n",
    "        self.bs = 500\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice\n",
    "\n",
    "The proposed slice based method, which estimate a slice of I(Z; T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.08379819989204407 loss val= 0.9518726468086243 adv_loss= (0.9930687546730042, 0.9925546050071716) time= 0.08807969093322754\n",
      "t= 50 loss= -0.1278180032968521 loss val= 0.025787904858589172 adv_loss= (0.23736535012722015, 0.158733069896698) time= 0.06826949119567871\n",
      "t= 100 loss= -0.13896586000919342 loss val= -0.09850331395864487 adv_loss= (0.17163525521755219, 0.04567597061395645) time= 0.06440305709838867\n",
      "t= 150 loss= -0.12926752865314484 loss val= -0.08577495813369751 adv_loss= (0.18564406037330627, 0.05951729416847229) time= 0.06843852996826172\n",
      "t= 200 loss= -0.08085440844297409 loss val= -0.06429358571767807 adv_loss= (0.17469634115695953, 0.08533938974142075) time= 0.06384634971618652\n",
      "t= 250 loss= -0.09801480919122696 loss val= -0.12339253723621368 adv_loss= (0.15174585580825806, 0.02621607296168804) time= 0.0688786506652832\n",
      "t= 300 loss= -0.03187737613916397 loss val= -0.09900850057601929 adv_loss= (0.1579950600862503, 0.04757241532206535) time= 0.0694875717163086\n",
      "t= 350 loss= -0.13023684918880463 loss val= -0.12996749579906464 adv_loss= (0.14540567994117737, 0.0196408461779356) time= 0.0691983699798584\n",
      "t= 400 loss= -0.03423965722322464 loss val= -0.1159197986125946 adv_loss= (0.14963984489440918, 0.03384661301970482) time= 0.08569502830505371\n",
      "t= 450 loss= 0.031360700726509094 loss val= -0.14895668625831604 adv_loss= (0.14851346611976624, 0.0007031560526229441) time= 0.09355998039245605\n",
      "best val loss= 0.14966824650764465 t= 499 best_t 462 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.998320460319519\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.021123548969626427 loss val= -0.022024203091859818 -0.022024203091859818\n",
      "finished: t= 100 loss= -0.8783303499221802 loss val= -0.06892836093902588 -0.08541350811719894\n",
      "finished: t= 200 loss= -0.9340795874595642 loss val= -0.059255342930555344 -0.08541350811719894\n",
      "finished: t= 300 loss= -0.9556503891944885 loss val= -0.05946008116006851 -0.08541350811719894\n",
      "finished: t= 400 loss= -0.9599483609199524 loss val= -0.058988239616155624 -0.08541350811719894\n",
      "finished: t= 500 loss= -0.9678977727890015 loss val= -0.05909137427806854 -0.08541350811719894\n",
      "[val] rho*(Z;T) = 0.08541350811719894\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9973097443580627\n",
      "[test] rho*(Z;T)= 0.10316655784845352\n"
     ]
    }
   ],
   "source": [
    "estimator = 'SLICE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 0.15\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.n_slice = 100\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial training\n",
    "\n",
    "Baseline methods that uses neural network (i.e. the *adversary*) to estimate I(Z; T) or its proxies. \n",
    "\n",
    "If the adversary is not trained sufficiently (controlled by *hyperparams.inner_epochs*), the learned Z will not be so fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.6693118810653687 loss val= 0.8527640700340271 adv_loss= -0.9893918037414551 time= 0.28438353538513184\n",
      "t= 50 loss= -0.8343992829322815 loss val= -0.8046528100967407 adv_loss= -0.04346594214439392 time= 0.2792022228240967\n",
      "t= 100 loss= -0.8413237929344177 loss val= -0.8395995497703552 adv_loss= -0.018952084705233574 time= 0.2871394157409668\n",
      "t= 150 loss= -0.6148027777671814 loss val= -0.6775297522544861 adv_loss= -0.16563567519187927 time= 0.27283668518066406\n",
      "t= 200 loss= -0.3584189713001251 loss val= -0.6378015279769897 adv_loss= -0.20467928051948547 time= 0.28690195083618164\n",
      "t= 250 loss= -0.2297525405883789 loss val= -0.6344290971755981 adv_loss= -0.20855972170829773 time= 0.27259278297424316\n",
      "t= 300 loss= -0.17110639810562134 loss val= -0.6288067102432251 adv_loss= -0.21423959732055664 time= 0.29013872146606445\n",
      "t= 350 loss= -0.21498364210128784 loss val= -0.6272209882736206 adv_loss= -0.2162967026233673 time= 0.2738804817199707\n",
      "t= 400 loss= -0.1487886905670166 loss val= -0.6255514621734619 adv_loss= -0.21798047423362732 time= 0.2588462829589844\n",
      "t= 450 loss= -0.16550230979919434 loss val= -0.6256684064865112 adv_loss= -0.21787288784980774 time= 0.2712397575378418\n",
      "best val loss= 0.8395995497703552 t= 499 best_t= 100 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9962480664253235\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.0024161851033568382 loss val= -0.017252303659915924 -0.017252303659915924\n",
      "finished: t= 100 loss= -0.8213714361190796 loss val= -0.15913480520248413 -0.1598941683769226\n",
      "finished: t= 200 loss= -0.8996984958648682 loss val= -0.16376055777072906 -0.16823622584342957\n",
      "finished: t= 300 loss= -0.9080036878585815 loss val= -0.16840404272079468 -0.1716625839471817\n",
      "finished: t= 400 loss= -0.9270086288452148 loss val= -0.16176283359527588 -0.1716625839471817\n",
      "finished: t= 500 loss= -0.932226836681366 loss val= -0.16099652647972107 -0.1716625839471817\n",
      "finished: t= 600 loss= -0.9358059167861938 loss val= -0.16599833965301514 -0.1716625839471817\n",
      "finished: t= 700 loss= -0.940215528011322 loss val= -0.16462011635303497 -0.1716625839471817\n",
      "[val] rho*(Z;T) = 0.1716625839471817\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9837172627449036\n",
      "[test] rho*(Z;T)= 0.21183161437511444\n"
     ]
    }
   ],
   "source": [
    "estimator = 'RENYI'                             # neural Renyi correlation\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.85\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 6                   # <-- this adjust the execution time of neural Renyi model\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -66.26215362548828 loss val= -0.23371586203575134 adv_loss= 0.21377435326576233 time= 1.561725378036499\n",
      "t= 50 loss= -5.484129428863525 loss val= -0.6484896540641785 adv_loss= 0.6053942441940308 time= 1.5729913711547852\n",
      "t= 100 loss= -5.089438438415527 loss val= -0.6892072558403015 adv_loss= 0.6407406330108643 time= 1.4096150398254395\n",
      "t= 150 loss= -0.7078949809074402 loss val= -0.6804920434951782 adv_loss= 0.6308146715164185 time= 1.518554925918579\n",
      "t= 200 loss= -0.6553541421890259 loss val= -0.6620994210243225 adv_loss= 0.6104956865310669 time= 1.5644960403442383\n",
      "t= 250 loss= -0.6213163137435913 loss val= -0.6264081597328186 adv_loss= 0.5759978890419006 time= 1.5502920150756836\n",
      "t= 300 loss= -0.6003984212875366 loss val= -0.608903169631958 adv_loss= 0.5632209777832031 time= 1.4453811645507812\n",
      "t= 350 loss= -0.5980075001716614 loss val= -0.609339714050293 adv_loss= 0.5509132146835327 time= 1.2585937976837158\n",
      "t= 400 loss= -0.5630080103874207 loss val= -0.5909461379051208 adv_loss= 0.537632942199707 time= 1.2164344787597656\n",
      "t= 450 loss= -0.5946201682090759 loss val= -0.5850524306297302 adv_loss= 0.5265039205551147 time= 1.2682230472564697\n",
      "best val loss= 0.6914790272712708 t= 499 best_t= 146 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9992027878761292\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.11865966767072678 loss val= -0.10285492986440659 -0.10285492986440659\n",
      "finished: t= 100 loss= -0.9079892039299011 loss val= -0.9234027862548828 -0.9234027862548828\n",
      "finished: t= 200 loss= -0.9307665824890137 loss val= -0.9285855889320374 -0.9495682120323181\n",
      "finished: t= 300 loss= -0.9642051458358765 loss val= -0.9494664072990417 -0.9559057354927063\n",
      "finished: t= 400 loss= -0.9556691646575928 loss val= -0.9567174911499023 -0.9610321521759033\n",
      "finished: t= 500 loss= -0.958961009979248 loss val= -0.9533572196960449 -0.9659338593482971\n",
      "finished: t= 600 loss= -0.9665395021438599 loss val= -0.9657266736030579 -0.9676136374473572\n",
      "finished: t= 700 loss= -0.977048933506012 loss val= -0.9671211242675781 -0.9711503982543945\n",
      "finished: t= 800 loss= -0.9781988263130188 loss val= -0.9691742062568665 -0.9723234176635742\n",
      "finished: t= 900 loss= -0.9605404734611511 loss val= -0.9700415134429932 -0.9744729995727539\n",
      "[val] rho*(Z;T) = 0.9746983647346497\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9978930354118347\n",
      "[test] rho*(Z;T)= 0.909979522228241\n"
     ]
    }
   ],
   "source": [
    "estimator = 'TC'                                # neural total correlation       \n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.05\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 20                  # <-- this adjust the execution time of neural Renyi model\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
