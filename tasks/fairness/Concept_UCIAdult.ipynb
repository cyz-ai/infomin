{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import USCensus, UCICrime\n",
    "from tasks.fairness.experiment import train, test\n",
    "from tasks.fairness.model import FairNet\n",
    "import utils_os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([20000, 16]) torch.Size([20000, 1])\n",
      "test torch.Size([2500, 16]) torch.Size([2500, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y, A = UCICrime.read_dataset(name='adult')\n",
    "X = torch.Tensor(X).to(device)                     # input data\n",
    "Y = torch.Tensor(Y).to(device)                     # target to predict\n",
    "A = torch.Tensor(A).to(device)                     # sensitive attribute\n",
    "assert X[0, -1] == A[0, -1]                        # the last index of x is also the sensitive attr \n",
    "assert X[0, -2] != A[0, -1]\n",
    "dim = 20\n",
    "n, d = X.size()\n",
    "n, K = Y.size()\n",
    "\n",
    "N = 20000\n",
    "x, y, a = X[0:N,:], Y[0:N, :], A[0:N, :]\n",
    "x = (x - x.mean(dim=0, keepdim=True))/x.std(dim=0, keepdim=True)\n",
    "x_test, y_test, a_test = X[N:N+2500,:], Y[N:N+2500, :], A[N:N+2500, :]\n",
    "x_test = (x_test - x_test.mean(dim=0, keepdim=True))/x_test.std(dim=0, keepdim=True)\n",
    "print('train', x.size(), y.size())\n",
    "print('test', x_test.size(), y_test.size())\n",
    "\n",
    "DATASET = 'UCIAdult'\n",
    "dim_z = 4*dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/A\n",
    "\n",
    "Plain model that has no constraint on I(Z; T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -9.857749938964844 loss val= -1.1813234090805054 adv_loss= tensor([0.], device='cuda:0') time= 0.0008447170257568359\n",
      "t= 50 loss= -9.96342658996582 loss val= -9.973118782043457 adv_loss= tensor([0.], device='cuda:0') time= 0.0008435249328613281\n",
      "t= 100 loss= -9.957209587097168 loss val= -9.987390518188477 adv_loss= tensor([0.], device='cuda:0') time= 0.0008449554443359375\n",
      "t= 150 loss= -9.970044136047363 loss val= -9.990811347961426 adv_loss= tensor([0.], device='cuda:0') time= 0.0008385181427001953\n",
      "t= 200 loss= -9.93735408782959 loss val= -9.993398666381836 adv_loss= tensor([0.], device='cuda:0') time= 0.0008389949798583984\n",
      "t= 250 loss= -9.951817512512207 loss val= -9.972981452941895 adv_loss= tensor([0.], device='cuda:0') time= 0.0008325576782226562\n",
      "t= 300 loss= -9.93704605102539 loss val= -9.986382484436035 adv_loss= tensor([0.], device='cuda:0') time= 0.0008449554443359375\n",
      "t= 350 loss= -9.964373588562012 loss val= -9.990212440490723 adv_loss= tensor([0.], device='cuda:0') time= 0.0008208751678466797\n",
      "t= 400 loss= -9.967499732971191 loss val= -9.988290786743164 adv_loss= tensor([0.], device='cuda:0') time= 0.0008347034454345703\n",
      "t= 450 loss= -9.976738929748535 loss val= -9.994783401489258 adv_loss= tensor([0.], device='cuda:0') time= 0.0008451938629150391\n",
      "best val loss= 9.996098518371582 t= 499 best_t 441 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9992501735687256\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.057064902037382126 loss val= -0.007814810611307621 -0.007814810611307621\n",
      "finished: t= 100 loss= -0.9650087952613831 loss val= -0.9422951340675354 -0.9686683416366577\n",
      "finished: t= 200 loss= -0.9517203569412231 loss val= -0.9741389751434326 -0.9763163328170776\n",
      "finished: t= 300 loss= -0.9792365431785583 loss val= -0.9808364510536194 -0.9813591837882996\n",
      "finished: t= 400 loss= -0.9812453985214233 loss val= -0.9842318296432495 -0.9842318296432495\n",
      "finished: t= 500 loss= -0.973889946937561 loss val= -0.98493492603302 -0.9852873682975769\n",
      "finished: t= 600 loss= -0.9763478636741638 loss val= -0.9848384857177734 -0.9864734411239624\n",
      "finished: t= 700 loss= -0.9799091815948486 loss val= -0.9847096800804138 -0.9868872761726379\n",
      "finished: t= 800 loss= -0.9864776730537415 loss val= -0.9868932962417603 -0.9881040453910828\n",
      "finished: t= 900 loss= -0.988853394985199 loss val= -0.9806995391845703 -0.9884318709373474\n",
      "[val] rho*(Z;T) = 0.9891101121902466\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9980000257492065\n",
      "[test] rho*(Z;T)= 0.9869883060455322\n"
     ]
    }
   ],
   "source": [
    "estimator = 'NONE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 10\n",
    "        self.lr = 1e-3\n",
    "        self.bs = 500\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice\n",
    "\n",
    "The proposed slice based method, which estimate a slice of I(Z; T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.11936375498771667 loss val= 0.9364299774169922 adv_loss= (0.9919296503067017, 0.991300106048584) time per iter= 0.2506539821624756\n",
      "t= 50 loss= -0.1354360729455948 loss val= 0.013980641961097717 adv_loss= (0.214186429977417, 0.14658018946647644) time per iter= 0.22774410247802734\n",
      "t= 100 loss= -0.09420060366392136 loss val= -0.09858796000480652 adv_loss= (0.159359410405159, 0.049193620681762695) time per iter= 0.22551226615905762\n",
      "t= 150 loss= -0.14069044589996338 loss val= -0.07006895542144775 adv_loss= (0.16730333864688873, 0.0755138099193573) time per iter= 0.23713040351867676\n",
      "t= 200 loss= -0.016740724444389343 loss val= -0.12110413610935211 adv_loss= (0.14782661199569702, 0.028454702347517014) time per iter= 0.22893381118774414\n",
      "t= 250 loss= 0.03495204448699951 loss val= -0.14713731408119202 adv_loss= (0.14595946669578552, 0.002224075375124812) time per iter= 0.271761417388916\n",
      "t= 300 loss= 0.03112076222896576 loss val= -0.10401973128318787 adv_loss= (0.1542695313692093, 0.04549143835902214) time per iter= 0.2296004295349121\n",
      "t= 350 loss= -0.060200467705726624 loss val= -0.13469886779785156 adv_loss= (0.15334078669548035, 0.014797547832131386) time per iter= 0.2502739429473877\n",
      "t= 400 loss= -0.011210322380065918 loss val= -0.10332302749156952 adv_loss= (0.14501340687274933, 0.04616762697696686) time per iter= 0.29787540435791016\n",
      "t= 450 loss= 0.028961896896362305 loss val= -0.08846890181303024 adv_loss= (0.15108038485050201, 0.06102142482995987) time per iter= 0.23616671562194824\n",
      "best val loss= 0.1484544724225998 t= 499 best_t= 308 early stopping= True\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9973386526107788\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "finished: t= 0 loss= -0.004912421107292175 loss val= -0.03074076771736145 -0.03074076771736145\n",
      "finished: t= 100 loss= -0.8663373589515686 loss val= -0.12279810756444931 -0.1353016197681427\n",
      "finished: t= 200 loss= -0.9338257312774658 loss val= -0.1186729371547699 -0.1353016197681427\n",
      "finished: t= 300 loss= -0.9539490342140198 loss val= -0.12148550152778625 -0.1353016197681427\n",
      "finished: t= 400 loss= -0.9651854634284973 loss val= -0.11179111897945404 -0.1353016197681427\n",
      "finished: t= 500 loss= -0.9697901010513306 loss val= -0.10893324762582779 -0.1353016197681427\n",
      "[val] rho*(Z;T) = 0.1353016197681427\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.996239185333252\n",
      "[test] rho*(Z;T)= 0.06830579787492752\n"
     ]
    }
   ],
   "source": [
    "estimator = 'SLICE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 0.15\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.n_slice = 100\n",
    "        self.inner_epochs = 0                   # <-- 0 means we don't optimise the slices, but you can also do so\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial training\n",
    "\n",
    "Baseline methods that uses neural network (i.e. the *adversary*) to estimate I(Z; T) or its proxies. \n",
    "\n",
    "If the adversary is not trained sufficiently (controlled by *hyperparams.inner_epochs*), the learned Z will not be so fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= 0.07830354571342468 loss val= 0.9647189974784851 adv_loss= -0.9817465543746948 time per iter= 0.8954341411590576\n",
      "t= 50 loss= -0.18962064385414124 loss val= -0.3322595953941345 adv_loss= -0.021536797285079956 time per iter= 0.8899922370910645\n",
      "t= 100 loss= -0.28281277418136597 loss val= -0.33801764249801636 adv_loss= -0.03141624107956886 time per iter= 0.8963000774383545\n",
      "t= 150 loss= -0.14592097699642181 loss val= -0.22914168238639832 adv_loss= -0.11960452795028687 time per iter= 0.8935518264770508\n",
      "t= 200 loss= -0.1158144623041153 loss val= -0.1758745163679123 adv_loss= -0.16743427515029907 time per iter= 0.8867254257202148\n",
      "t= 250 loss= 0.11445313692092896 loss val= -0.10944932699203491 adv_loss= -0.22993695735931396 time per iter= 0.8841004371643066\n",
      "t= 300 loss= 0.36939120292663574 loss val= -0.06791889667510986 adv_loss= -0.2741472125053406 time per iter= 0.8929531574249268\n",
      "t= 350 loss= 0.37139758467674255 loss val= -0.04945150017738342 adv_loss= -0.29358190298080444 time per iter= 0.8878903388977051\n",
      "t= 400 loss= 0.4666096866130829 loss val= -0.04251605272293091 adv_loss= -0.30023524165153503 time per iter= 0.8876066207885742\n",
      "t= 450 loss= 0.4169107675552368 loss val= -0.03367301821708679 adv_loss= -0.3099433481693268 time per iter= 0.40369606018066406\n",
      "best val loss= 0.34838706254959106 t= 499 best_t= 102 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9836333990097046\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.0202195942401886 loss val= -0.02079751156270504 -0.02079751156270504\n",
      "finished: t= 100 loss= -0.7397270202636719 loss val= -0.21952775120735168 -0.23108798265457153\n",
      "finished: t= 200 loss= -0.8042337894439697 loss val= -0.23376885056495667 -0.23982109129428864\n",
      "finished: t= 300 loss= -0.848057746887207 loss val= -0.23581832647323608 -0.24236197769641876\n",
      "finished: t= 400 loss= -0.8707419633865356 loss val= -0.23926320672035217 -0.24403296411037445\n",
      "finished: t= 500 loss= -0.8733287453651428 loss val= -0.23263540863990784 -0.24403296411037445\n",
      "finished: t= 600 loss= -0.8943076133728027 loss val= -0.2393120676279068 -0.24712014198303223\n",
      "finished: t= 700 loss= -0.8869388103485107 loss val= -0.2317885309457779 -0.24712014198303223\n",
      "finished: t= 800 loss= -0.8852937817573547 loss val= -0.23801937699317932 -0.24712014198303223\n",
      "finished: t= 900 loss= -0.8569535613059998 loss val= -0.23852621018886566 -0.24712014198303223\n",
      "[val] rho*(Z;T) = 0.24712014198303223\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.962961733341217\n",
      "[test] rho*(Z;T)= 0.2904266119003296\n"
     ]
    }
   ],
   "source": [
    "estimator = 'RENYI'                             # neural Renyi correlation\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.35\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 3                   # <-- this adjust the execution time\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.6360607743263245 loss val= -0.5947480797767639 adv_loss= 0.5675549507141113 time per iter= 0.750281810760498\n",
      "t= 50 loss= -0.7432966828346252 loss val= -0.7423279881477356 adv_loss= 0.6918755769729614 time per iter= 0.7195310592651367\n",
      "t= 100 loss= -0.7386649250984192 loss val= -0.7399130463600159 adv_loss= 0.6906622648239136 time per iter= 1.4694995880126953\n",
      "t= 150 loss= -0.7377430200576782 loss val= -0.7405813336372375 adv_loss= 0.692774772644043 time per iter= 1.3388607501983643\n",
      "t= 200 loss= -0.6815589070320129 loss val= -0.7574877142906189 adv_loss= 0.7073756456375122 time per iter= 1.5055198669433594\n",
      "t= 250 loss= -0.7017704248428345 loss val= -0.7684246301651001 adv_loss= 0.7195345759391785 time per iter= 1.406221628189087\n",
      "t= 300 loss= -0.6817378401756287 loss val= -0.7648965120315552 adv_loss= 0.7175062894821167 time per iter= 1.3466072082519531\n",
      "t= 350 loss= -0.6883325576782227 loss val= -0.7841498851776123 adv_loss= 0.7311117649078369 time per iter= 1.6012518405914307\n",
      "t= 400 loss= -0.6996973752975464 loss val= -0.781103789806366 adv_loss= 0.7352219223976135 time per iter= 1.4565534591674805\n",
      "t= 450 loss= -0.6574884653091431 loss val= -0.9089346528053284 adv_loss= 0.8687845468521118 time per iter= 1.452808141708374\n",
      "best val loss= 1.0683892965316772 t= 499 best_t= 499 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9794503450393677\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "finished: t= 0 loss= -0.03900747001171112 loss val= -0.019080203026533127 -0.019080203026533127\n",
      "finished: t= 100 loss= -0.8872350454330444 loss val= -0.22108468413352966 -0.26149624586105347\n",
      "finished: t= 200 loss= -0.9387814402580261 loss val= -0.19217225909233093 -0.26149624586105347\n",
      "finished: t= 300 loss= -0.9498807191848755 loss val= -0.18694671988487244 -0.26149624586105347\n",
      "finished: t= 400 loss= -0.9658805131912231 loss val= -0.18040601909160614 -0.26149624586105347\n",
      "finished: t= 500 loss= -0.9678027033805847 loss val= -0.18166035413742065 -0.26149624586105347\n",
      "[val] rho*(Z;T) = 0.26149624586105347\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9685083031654358\n",
      "[test] rho*(Z;T)= 0.17565742135047913\n"
     ]
    }
   ],
   "source": [
    "estimator = 'TC'                                # neural total correlation       \n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.05\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 5                   # <-- this adjust the execution time\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
