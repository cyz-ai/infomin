{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import USCensus, UCICrime\n",
    "from tasks.fairness.experiment import train, test\n",
    "from tasks.fairness.model import FairNet\n",
    "\n",
    "import utils_os, utils_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([20000, 32]) torch.Size([20000, 1])\n",
      "test torch.Size([2500, 32]) torch.Size([2500, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y, A = USCensus.read_tract(label='Proverty', sensitive_attribute='Gender')\n",
    "X = torch.Tensor(X).to(device)                     # input data\n",
    "Y = torch.Tensor(Y).to(device)                     # target to predict\n",
    "A = torch.Tensor(A).to(device)                     # sensitive attribute\n",
    "assert X[0, -1] == A[0, -1]                        # the last index of x is also the sensitive attr \n",
    "assert X[0, -2] != A[0, -1]\n",
    "dim = 20\n",
    "n, d = X.size()\n",
    "n, K = Y.size()\n",
    "\n",
    "N = 20000\n",
    "x, y, a = X[0:N,:], Y[0:N, :], A[0:N, :]\n",
    "x = (x - x.mean(dim=0, keepdim=True))/x.std(dim=0, keepdim=True)\n",
    "x_test, y_test, a_test = X[N:N+2500,:], Y[N:N+2500, :], A[N:N+2500, :]\n",
    "x_test = (x_test - x_test.mean(dim=0, keepdim=True))/x_test.std(dim=0, keepdim=True)\n",
    "print('train', x.size(), y.size())\n",
    "print('test', x_test.size(), y_test.size())\n",
    "\n",
    "DATASET = 'USCensus'\n",
    "dim_z = 4*dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/A\n",
    "\n",
    "Plain model that has no constraint on I(Z; T). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -9.520732879638672 loss val= -5.054341793060303 adv_loss= tensor([0.], device='cuda:1') time= 0.0008563995361328125\n",
      "t= 50 loss= -9.793397903442383 loss val= -9.495684623718262 adv_loss= tensor([0.], device='cuda:1') time= 0.0008587837219238281\n",
      "t= 100 loss= -9.866706848144531 loss val= -9.397472381591797 adv_loss= tensor([0.], device='cuda:1') time= 0.0008535385131835938\n",
      "t= 150 loss= -9.891358375549316 loss val= -9.36882495880127 adv_loss= tensor([0.], device='cuda:1') time= 0.0008504390716552734\n",
      "t= 200 loss= -9.893041610717773 loss val= -9.363776206970215 adv_loss= tensor([0.], device='cuda:1') time= 0.0008552074432373047\n",
      "t= 250 loss= -9.887506484985352 loss val= -9.363200187683105 adv_loss= tensor([0.], device='cuda:1') time= 0.0008544921875\n",
      "t= 300 loss= -9.869596481323242 loss val= -9.3630952835083 adv_loss= tensor([0.], device='cuda:1') time= 0.0008604526519775391\n",
      "t= 350 loss= -9.868520736694336 loss val= -9.363089561462402 adv_loss= tensor([0.], device='cuda:1') time= 0.0008516311645507812\n",
      "t= 400 loss= -9.876276969909668 loss val= -9.363085746765137 adv_loss= tensor([0.], device='cuda:1') time= 0.0008530616760253906\n",
      "t= 450 loss= -9.886688232421875 loss val= -9.363068580627441 adv_loss= tensor([0.], device='cuda:1') time= 0.0008466243743896484\n",
      "best val loss= 9.398459434509277 t= 499 best_t 102 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9423488974571228\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.030204692855477333 loss val= -0.07122346758842468 -0.07122346758842468\n",
      "finished: t= 100 loss= -0.9354404807090759 loss val= -0.8161199688911438 -0.8161199688911438\n",
      "finished: t= 200 loss= -0.9376276135444641 loss val= -0.8276835083961487 -0.8355091214179993\n",
      "finished: t= 300 loss= -0.9629600644111633 loss val= -0.8180305361747742 -0.842097282409668\n",
      "finished: t= 400 loss= -0.9652586579322815 loss val= -0.8437421917915344 -0.8487616777420044\n",
      "finished: t= 500 loss= -0.9754544496536255 loss val= -0.8462822437286377 -0.8528635501861572\n",
      "finished: t= 600 loss= -0.9502597451210022 loss val= -0.8537444472312927 -0.853851318359375\n",
      "finished: t= 700 loss= -0.9722003936767578 loss val= -0.853442907333374 -0.855993926525116\n",
      "finished: t= 800 loss= -0.9768210053443909 loss val= -0.8468371629714966 -0.85670006275177\n",
      "finished: t= 900 loss= -0.9733311533927917 loss val= -0.8516961336135864 -0.8582155704498291\n",
      "[val] rho*(Z;T) = 0.859952986240387\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.950739324092865\n",
      "[test] rho*(Z;T)= 0.8124213218688965\n"
     ]
    }
   ],
   "source": [
    "estimator = 'NONE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 10\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice\n",
    "\n",
    "The proposed slice based method, which estimate a slice of I(Z; T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.32833436131477356 loss val= 0.8138784170150757 adv_loss= (0.9428901076316833, 0.9410136938095093) time= 0.0967864990234375\n",
      "t= 50 loss= -0.3027324378490448 loss val= -0.2206546664237976 adv_loss= (0.17648135125637054, 0.0934160128235817) time= 0.07204580307006836\n",
      "t= 100 loss= -0.30741024017333984 loss val= -0.2498663067817688 adv_loss= (0.17200900614261627, 0.07138828188180923) time= 0.07196831703186035\n",
      "t= 150 loss= -0.26396113634109497 loss val= -0.2812604606151581 adv_loss= (0.16744105517864227, 0.04428320378065109) time= 0.07210969924926758\n",
      "t= 200 loss= -0.23471036553382874 loss val= -0.27446249127388 adv_loss= (0.16574694216251373, 0.047728877514600754) time= 0.07109284400939941\n",
      "t= 250 loss= -0.19777096807956696 loss val= -0.22445540130138397 adv_loss= (0.16239887475967407, 0.10240037739276886) time= 0.07114219665527344\n",
      "t= 300 loss= -0.2553684711456299 loss val= -0.3185093104839325 adv_loss= (0.14165353775024414, 0.006020902190357447) time= 0.07230401039123535\n",
      "t= 350 loss= -0.2832892835140228 loss val= -0.30055180191993713 adv_loss= (0.14328362047672272, 0.026412541046738625) time= 0.07695698738098145\n",
      "t= 400 loss= -0.1936773657798767 loss val= -0.30181241035461426 adv_loss= (0.1446242779493332, 0.025232313200831413) time= 0.07219433784484863\n",
      "t= 450 loss= -0.1873052567243576 loss val= -0.28746265172958374 adv_loss= (0.14710186421871185, 0.039772409945726395) time= 0.07226967811584473\n",
      "best val loss= 0.32667145133018494 t= 499 best_t 343 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9338613748550415\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.04019828140735626 loss val= -0.02533925510942936 -0.02533925510942936\n",
      "finished: t= 100 loss= -0.8335146903991699 loss val= -0.04039508104324341 -0.06348026543855667\n",
      "finished: t= 200 loss= -0.8873996138572693 loss val= -0.0448746494948864 -0.06348026543855667\n",
      "finished: t= 300 loss= -0.940857470035553 loss val= -0.046329714357852936 -0.06348026543855667\n",
      "finished: t= 400 loss= -0.9568694233894348 loss val= -0.04470027983188629 -0.06348026543855667\n",
      "finished: t= 500 loss= -0.9557152390480042 loss val= -0.042036961764097214 -0.06348026543855667\n",
      "[val] rho*(Z;T) = 0.06348026543855667\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9567016959190369\n",
      "[test] rho*(Z;T)= 0.05737484246492386\n"
     ]
    }
   ],
   "source": [
    "estimator = 'SLICE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 0.35\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.n_slice = 100\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial training\n",
    "\n",
    "Baseline methods that uses neural network (i.e. the 'adversary') to estimate I(Z; T) or its proxies. \n",
    "\n",
    "If the adversary is not trained sufficiently (tuned by inner_epochs), the learned Z will not be so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.0964183360338211 loss val= 0.8825427293777466 adv_loss= -0.9419568181037903 time= 0.14068889617919922\n",
      "t= 50 loss= -0.07684874534606934 loss val= -0.1205780953168869 adv_loss= -0.04392237216234207 time= 0.18235993385314941\n",
      "t= 100 loss= -0.13804253935813904 loss val= -0.11862627416849136 adv_loss= -0.05400653928518295 time= 0.17664313316345215\n",
      "t= 150 loss= -0.06514017283916473 loss val= -0.13622711598873138 adv_loss= -0.05854476988315582 time= 0.188917875289917\n",
      "t= 200 loss= 0.14819596707820892 loss val= 0.07584838569164276 adv_loss= -0.20300178229808807 time= 0.15832042694091797\n",
      "t= 250 loss= 0.31101691722869873 loss val= 0.09185196459293365 adv_loss= -0.21724757552146912 time= 0.15630102157592773\n",
      "t= 300 loss= 0.3326883912086487 loss val= 0.10909204185009003 adv_loss= -0.23380279541015625 time= 0.17449617385864258\n",
      "t= 350 loss= 0.32776734232902527 loss val= 0.11558926105499268 adv_loss= -0.24150541424751282 time= 0.18619823455810547\n",
      "t= 400 loss= 0.3161201477050781 loss val= 0.11799728870391846 adv_loss= -0.2437557727098465 time= 0.17039823532104492\n",
      "t= 450 loss= 0.3247781991958618 loss val= 0.11778776347637177 adv_loss= -0.24362130463123322 time= 0.18009233474731445\n",
      "best val loss= 0.13622711598873138 t= 499 best_t= 150 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9453339576721191\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.01586153171956539 loss val= -0.03844231367111206 -0.03844231367111206\n",
      "finished: t= 100 loss= -0.7103323340415955 loss val= -0.297630250453949 -0.297630250453949\n",
      "finished: t= 200 loss= -0.7090802788734436 loss val= -0.319677472114563 -0.3255171775817871\n",
      "finished: t= 300 loss= -0.7379411458969116 loss val= -0.33840495347976685 -0.34349125623703003\n",
      "finished: t= 400 loss= -0.8160399198532104 loss val= -0.3536054790019989 -0.35614171624183655\n",
      "finished: t= 500 loss= -0.7578352689743042 loss val= -0.3658583462238312 -0.3658583462238312\n",
      "finished: t= 600 loss= -0.8397824168205261 loss val= -0.35063880681991577 -0.37146610021591187\n",
      "finished: t= 700 loss= -0.8184825778007507 loss val= -0.3697751462459564 -0.37772953510284424\n",
      "finished: t= 800 loss= -0.8205800652503967 loss val= -0.37067103385925293 -0.3856281638145447\n",
      "finished: t= 900 loss= -0.8309078812599182 loss val= -0.37949618697166443 -0.386542409658432\n",
      "[val] rho*(Z;T) = 0.39433741569519043\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9588188529014587\n",
      "[test] rho*(Z;T)= 0.39997005462646484\n"
     ]
    }
   ],
   "source": [
    "estimator = 'RENYI'                            # neural Renyi correlation\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.15\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 4                  # <-- this adjust the execution time of neural Renyi model\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -21.613868713378906 loss val= -0.42932307720184326 adv_loss= 0.4191444516181946 time= 0.6922318935394287\n",
      "t= 50 loss= -0.7624861001968384 loss val= -0.7328280806541443 adv_loss= 0.6875702142715454 time= 0.689429759979248\n",
      "t= 100 loss= -0.7343903183937073 loss val= -0.7385129332542419 adv_loss= 0.6911075115203857 time= 0.7346620559692383\n",
      "t= 150 loss= -0.7233610153198242 loss val= -0.7395967245101929 adv_loss= 0.6910511255264282 time= 0.672919750213623\n",
      "t= 200 loss= -0.7070338129997253 loss val= -0.7488800883293152 adv_loss= 0.6995567083358765 time= 0.7108669281005859\n",
      "t= 250 loss= -0.6999318599700928 loss val= -0.7569356560707092 adv_loss= 0.706995964050293 time= 0.7031376361846924\n",
      "t= 300 loss= -0.6850447058677673 loss val= -0.7667465209960938 adv_loss= 0.7123385071754456 time= 0.7192873954772949\n",
      "t= 350 loss= -0.6666769981384277 loss val= -0.7731035947799683 adv_loss= 0.723172664642334 time= 0.7463462352752686\n",
      "t= 400 loss= -0.6835117340087891 loss val= -0.7772664427757263 adv_loss= 0.7276890873908997 time= 0.7238037586212158\n",
      "t= 450 loss= -0.6847552061080933 loss val= -0.786439061164856 adv_loss= 0.7353742122650146 time= 0.7226371765136719\n",
      "best val loss= 0.7965386509895325 t= 499 best_t= 498 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9426290392875671\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.05607163906097412 loss val= -0.01452296506613493 -0.01452296506613493\n",
      "finished: t= 100 loss= -0.48488110303878784 loss val= -0.2189532220363617 -0.2189532220363617\n",
      "finished: t= 200 loss= -0.5090804100036621 loss val= -0.2277822196483612 -0.27981650829315186\n",
      "finished: t= 300 loss= -0.5997895002365112 loss val= -0.3002236783504486 -0.3152957856655121\n",
      "finished: t= 400 loss= -0.5852450132369995 loss val= -0.3013667166233063 -0.32379665970802307\n",
      "finished: t= 500 loss= -0.6926960349082947 loss val= -0.312893271446228 -0.33934956789016724\n",
      "finished: t= 600 loss= -0.7000653147697449 loss val= -0.3377543091773987 -0.36612921953201294\n",
      "finished: t= 700 loss= -0.606292724609375 loss val= -0.33807653188705444 -0.37448668479919434\n",
      "finished: t= 800 loss= -0.7472547888755798 loss val= -0.3652130365371704 -0.3811866044998169\n",
      "finished: t= 900 loss= -0.7345001697540283 loss val= -0.37366563081741333 -0.3863298296928406\n",
      "[val] rho*(Z;T) = 0.39890822768211365\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.957013726234436\n",
      "[test] rho*(Z;T)= 0.3114304840564728\n"
     ]
    }
   ],
   "source": [
    "estimator = 'TC'                                # neural total correlation       \n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage         \n",
    "        self.beta = 0.05\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 10                  # <-- this adjust the execution time of neural Renyi model\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
