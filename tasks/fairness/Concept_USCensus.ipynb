{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import USCensus, UCICrime\n",
    "from tasks.fairness.experiment import train, test\n",
    "from tasks.fairness.model import FairNet\n",
    "\n",
    "import utils_os, utils_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([20000, 32]) torch.Size([20000, 1])\n",
      "test torch.Size([2500, 32]) torch.Size([2500, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y, A = USCensus.read_tract(label='Proverty', sensitive_attribute='Gender')\n",
    "X = torch.Tensor(X).to(device)                     # input data\n",
    "Y = torch.Tensor(Y).to(device)                     # target to predict\n",
    "A = torch.Tensor(A).to(device)                     # sensitive attribute\n",
    "assert X[0, -1] == A[0, -1]                        # the last index of x is also the sensitive attr \n",
    "assert X[0, -2] != A[0, -1]\n",
    "dim = 20\n",
    "n, d = X.size()\n",
    "n, K = Y.size()\n",
    "\n",
    "N = 20000\n",
    "x, y, a = X[0:N,:], Y[0:N, :], A[0:N, :]\n",
    "x = (x - x.mean(dim=0, keepdim=True))/x.std(dim=0, keepdim=True)\n",
    "x_test, y_test, a_test = X[N:N+2500,:], Y[N:N+2500, :], A[N:N+2500, :]\n",
    "x_test = (x_test - x_test.mean(dim=0, keepdim=True))/x_test.std(dim=0, keepdim=True)\n",
    "print('train', x.size(), y.size())\n",
    "print('test', x_test.size(), y_test.size())\n",
    "\n",
    "DATASET = 'USCensus'\n",
    "dim_z = 4*dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/A\n",
    "\n",
    "Plain model that has no constraint on I(Z; T). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -9.520732879638672 loss val= -5.054341793060303 adv_loss= tensor([0.], device='cuda:1') time= 0.0008563995361328125\n",
      "t= 50 loss= -9.793397903442383 loss val= -9.495684623718262 adv_loss= tensor([0.], device='cuda:1') time= 0.0008587837219238281\n",
      "t= 100 loss= -9.866706848144531 loss val= -9.397472381591797 adv_loss= tensor([0.], device='cuda:1') time= 0.0008535385131835938\n",
      "t= 150 loss= -9.891358375549316 loss val= -9.36882495880127 adv_loss= tensor([0.], device='cuda:1') time= 0.0008504390716552734\n",
      "t= 200 loss= -9.893041610717773 loss val= -9.363776206970215 adv_loss= tensor([0.], device='cuda:1') time= 0.0008552074432373047\n",
      "t= 250 loss= -9.887506484985352 loss val= -9.363200187683105 adv_loss= tensor([0.], device='cuda:1') time= 0.0008544921875\n",
      "t= 300 loss= -9.869596481323242 loss val= -9.3630952835083 adv_loss= tensor([0.], device='cuda:1') time= 0.0008604526519775391\n",
      "t= 350 loss= -9.868520736694336 loss val= -9.363089561462402 adv_loss= tensor([0.], device='cuda:1') time= 0.0008516311645507812\n",
      "t= 400 loss= -9.876276969909668 loss val= -9.363085746765137 adv_loss= tensor([0.], device='cuda:1') time= 0.0008530616760253906\n",
      "t= 450 loss= -9.886688232421875 loss val= -9.363068580627441 adv_loss= tensor([0.], device='cuda:1') time= 0.0008466243743896484\n",
      "best val loss= 9.398459434509277 t= 499 best_t 102 (early stopping was used.)\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9423488974571228\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.030204692855477333 loss val= -0.07122346758842468 -0.07122346758842468\n",
      "finished: t= 100 loss= -0.9354404807090759 loss val= -0.8161199688911438 -0.8161199688911438\n",
      "finished: t= 200 loss= -0.9376276135444641 loss val= -0.8276835083961487 -0.8355091214179993\n",
      "finished: t= 300 loss= -0.9629600644111633 loss val= -0.8180305361747742 -0.842097282409668\n",
      "finished: t= 400 loss= -0.9652586579322815 loss val= -0.8437421917915344 -0.8487616777420044\n",
      "finished: t= 500 loss= -0.9754544496536255 loss val= -0.8462822437286377 -0.8528635501861572\n",
      "finished: t= 600 loss= -0.9502597451210022 loss val= -0.8537444472312927 -0.853851318359375\n",
      "finished: t= 700 loss= -0.9722003936767578 loss val= -0.853442907333374 -0.855993926525116\n",
      "finished: t= 800 loss= -0.9768210053443909 loss val= -0.8468371629714966 -0.85670006275177\n",
      "finished: t= 900 loss= -0.9733311533927917 loss val= -0.8516961336135864 -0.8582155704498291\n",
      "[val] rho*(Z;T) = 0.859952986240387\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.950739324092865\n",
      "[test] rho*(Z;T)= 0.8124213218688965\n"
     ]
    }
   ],
   "source": [
    "estimator = 'NONE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 10\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice\n",
    "\n",
    "The proposed slice based method, which estimate a slice of I(Z; T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.6070358753204346 loss val= 0.8509424328804016 adv_loss= (0.9503340125083923, 0.9500017166137695) time per iter= 0.2262434959411621\n",
      "t= 50 loss= -0.7124919891357422 loss val= -0.547791600227356 adv_loss= (0.2390560507774353, 0.14599670469760895) time per iter= 0.248460054397583\n",
      "t= 100 loss= -0.645367443561554 loss val= -0.6072866320610046 adv_loss= (0.18458671867847443, 0.09757854044437408) time per iter= 0.2509024143218994\n",
      "t= 150 loss= -0.670754611492157 loss val= -0.6361450552940369 adv_loss= (0.1766381859779358, 0.06653881818056107) time per iter= 0.27583789825439453\n",
      "t= 200 loss= -0.6228980422019958 loss val= -0.6322997212409973 adv_loss= (0.15864570438861847, 0.06550151854753494) time per iter= 0.2328033447265625\n",
      "t= 250 loss= -0.6714261770248413 loss val= -0.6992306709289551 adv_loss= (0.146018385887146, 0.004361852537840605) time per iter= 0.20165681838989258\n",
      "t= 300 loss= -0.6040209531784058 loss val= -0.613516628742218 adv_loss= (0.1632571518421173, 0.09544043987989426) time per iter= 0.24684739112854004\n",
      "t= 350 loss= -0.5795727372169495 loss val= -0.6853143572807312 adv_loss= (0.15503168106079102, 0.024910680949687958) time per iter= 0.20128273963928223\n",
      "t= 400 loss= -0.6604716777801514 loss val= -0.6624704599380493 adv_loss= (0.14468052983283997, 0.04965514317154884) time per iter= 0.20101666450500488\n",
      "t= 450 loss= -0.6283735036849976 loss val= -0.7066769599914551 adv_loss= (0.1464957296848297, 0.005618231371045113) time per iter= 0.23198318481445312\n",
      "best val loss= 0.7114148736000061 t= 499 best_t= 494 early stopping= True\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9471838474273682\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "finished: t= 0 loss= -0.010437819175422192 loss val= -0.007621064782142639 -0.007621064782142639\n",
      "finished: t= 100 loss= -0.8614041209220886 loss val= -0.024067405611276627 -0.03366197273135185\n",
      "finished: t= 200 loss= -0.9281507134437561 loss val= -0.019866475835442543 -0.03366197273135185\n",
      "finished: t= 300 loss= -0.9500631093978882 loss val= -0.017084293067455292 -0.03366197273135185\n",
      "finished: t= 400 loss= -0.9500327706336975 loss val= -0.019284341484308243 -0.03366197273135185\n",
      "finished: t= 500 loss= -0.955348014831543 loss val= -0.017050376161932945 -0.03366197273135185\n",
      "[val] rho*(Z;T) = 0.03366197273135185\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.962736964225769\n",
      "[test] rho*(Z;T)= 0.010313605889678001\n"
     ]
    }
   ],
   "source": [
    "estimator = 'SLICE'\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.beta = 0.75\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.n_slice = 100\n",
    "        self.inner_epochs = 0                   # <-- 0 means we don't optimise the slices, but you can also do so\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial training\n",
    "\n",
    "Baseline methods that uses neural network (i.e. the 'adversary') to estimate I(Z; T) or its proxies. \n",
    "\n",
    "If the adversary is not trained sufficiently (tuned by inner_epochs), the learned Z will not be so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.0809314101934433 loss val= 0.7632180452346802 adv_loss= -0.8326592445373535 time per iter= 0.694091796875\n",
      "t= 50 loss= -0.14120878279209137 loss val= -0.09934559464454651 adv_loss= -0.053575098514556885 time per iter= 0.641768217086792\n",
      "t= 100 loss= -0.06660383939743042 loss val= -0.03902415931224823 adv_loss= -0.10181170701980591 time per iter= 0.28841352462768555\n",
      "t= 150 loss= 0.05179755389690399 loss val= 0.05810964107513428 adv_loss= -0.17670926451683044 time per iter= 0.2869553565979004\n",
      "t= 200 loss= 0.15463517606258392 loss val= 0.1431826651096344 adv_loss= -0.28230786323547363 time per iter= 0.278562068939209\n",
      "t= 250 loss= 0.36782699823379517 loss val= 0.1845712810754776 adv_loss= -0.31612634658813477 time per iter= 0.2640187740325928\n",
      "t= 300 loss= 0.308788001537323 loss val= 0.22461208701133728 adv_loss= -0.35160624980926514 time per iter= 0.28175950050354004\n",
      "t= 350 loss= 0.37271440029144287 loss val= 0.24415381252765656 adv_loss= -0.36288535594940186 time per iter= 0.2807807922363281\n",
      "t= 400 loss= 0.34097030758857727 loss val= 0.27731892466545105 adv_loss= -0.39267343282699585 time per iter= 0.2985258102416992\n",
      "t= 450 loss= 0.41311997175216675 loss val= 0.2779189348220825 adv_loss= -0.39255785942077637 time per iter= 0.3081238269805908\n",
      "best val loss= 0.11906727403402328 t= 499 best_t= 114 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9451829791069031\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "T= 1000\n",
      "finished: t= 0 loss= -0.031660500913858414 loss val= -0.02440623752772808 -0.02440623752772808\n",
      "finished: t= 100 loss= -0.7200922966003418 loss val= -0.42777127027511597 -0.4588157534599304\n",
      "finished: t= 200 loss= -0.7127841711044312 loss val= -0.4637968838214874 -0.48095816373825073\n",
      "finished: t= 300 loss= -0.7615404725074768 loss val= -0.48002713918685913 -0.4862639904022217\n",
      "finished: t= 400 loss= -0.7864819765090942 loss val= -0.48791950941085815 -0.4985886812210083\n",
      "finished: t= 500 loss= -0.8060824275016785 loss val= -0.4233630895614624 -0.5008896589279175\n",
      "finished: t= 600 loss= -0.8148471713066101 loss val= -0.46836143732070923 -0.508592963218689\n",
      "finished: t= 700 loss= -0.8198289275169373 loss val= -0.47531142830848694 -0.5119073390960693\n",
      "finished: t= 800 loss= -0.7691217064857483 loss val= -0.4799318313598633 -0.5154653191566467\n",
      "finished: t= 900 loss= -0.8572599291801453 loss val= -0.49602383375167847 -0.5167921781539917\n",
      "[val] rho*(Z;T) = 0.5202819108963013\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9355237483978271\n",
      "[test] rho*(Z;T)= 0.4191119372844696\n"
     ]
    }
   ],
   "source": [
    "estimator = 'RENYI'                            # neural Renyi correlation\n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                # <-- don't use early stopping as the adversary is not mature at early stage\n",
    "        self.beta = 0.15\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 2                  # <-- this adjust the execution time\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= 0 loss= -0.7807778716087341 loss val= -0.7066316604614258 adv_loss= 0.6822531223297119 time per iter= 1.1141557693481445\n",
      "t= 50 loss= -0.7901327013969421 loss val= -0.7851606607437134 adv_loss= 0.6905874609947205 time per iter= 1.1358845233917236\n",
      "t= 100 loss= -0.7918014526367188 loss val= -0.7872661352157593 adv_loss= 0.6914178133010864 time per iter= 1.1185259819030762\n",
      "t= 150 loss= -0.7863660454750061 loss val= -0.7877463102340698 adv_loss= 0.6915872097015381 time per iter= 1.1400105953216553\n",
      "t= 200 loss= -0.7805623412132263 loss val= -0.7862117886543274 adv_loss= 0.6908053159713745 time per iter= 1.1238410472869873\n",
      "t= 250 loss= -0.7739601731300354 loss val= -0.7857621908187866 adv_loss= 0.6910184621810913 time per iter= 0.8811068534851074\n",
      "t= 300 loss= -0.7737019658088684 loss val= -0.791662335395813 adv_loss= 0.6955823302268982 time per iter= 1.1384270191192627\n",
      "t= 350 loss= -0.7518147826194763 loss val= -0.7927985191345215 adv_loss= 0.6972127556800842 time per iter= 0.958486795425415\n",
      "t= 400 loss= -0.7550243735313416 loss val= -0.7925900816917419 adv_loss= 0.6977384090423584 time per iter= 0.9985296726226807\n",
      "t= 450 loss= -0.7628015279769897 loss val= -0.800107479095459 adv_loss= 0.7069251537322998 time per iter= 0.923351526260376\n",
      "best val loss= 0.8142761588096619 t= 499 best_t= 499 early stopping= False\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;Y)...\n",
      "[val] rho*(Z;Y)= 0.9491789937019348\n",
      "\n",
      "\n",
      "training network to estimate rho*(Z;T)...\n",
      "finished: t= 0 loss= -0.0005366492550820112 loss val= -0.044824618846178055 -0.044824618846178055\n",
      "finished: t= 100 loss= -0.5904754996299744 loss val= -0.22512315213680267 -0.2300429493188858\n",
      "finished: t= 200 loss= -0.6319879293441772 loss val= -0.22158664464950562 -0.253312349319458\n",
      "finished: t= 300 loss= -0.46820709109306335 loss val= -0.22052475810050964 -0.2618076801300049\n",
      "finished: t= 400 loss= -0.7107495665550232 loss val= -0.24858644604682922 -0.27243468165397644\n",
      "finished: t= 500 loss= -0.7830144762992859 loss val= -0.2563764452934265 -0.2830049395561218\n",
      "finished: t= 600 loss= -0.7295607924461365 loss val= -0.281816303730011 -0.29296422004699707\n",
      "finished: t= 700 loss= -0.7578577995300293 loss val= -0.286616712808609 -0.29835009574890137\n",
      "finished: t= 800 loss= -0.8216261863708496 loss val= -0.28471165895462036 -0.30478477478027344\n",
      "finished: t= 900 loss= -0.7387507557868958 loss val= -0.30294591188430786 -0.31114035844802856\n",
      "[val] rho*(Z;T) = 0.31697729229927063\n",
      "\n",
      "\n",
      "[test] rho*(Z;Y)= 0.9452938437461853\n",
      "[test] rho*(Z;T)= 0.20810890197753906\n"
     ]
    }
   ],
   "source": [
    "estimator = 'TC'                                # neural total correlation       \n",
    "\n",
    "class Hyperparams(utils_os.ConfigDict):\n",
    "    def __init__(self): \n",
    "        self.estimator = estimator\n",
    "        self.early_stop = False                 # <-- don't use early stopping as the adversary is not mature at early stage         \n",
    "        self.beta = 0.10\n",
    "        self.lr = 5e-4\n",
    "        self.bs = 500\n",
    "        self.inner_epochs = 3                   # <-- this adjust the execution time\n",
    "        self.dim_learnt = dim_z\n",
    "        self.dim_sensitive = 1\n",
    "hyperparams=Hyperparams()\n",
    "\n",
    "net = FairNet(architecture=[d, 10*dim, 10*dim, 4*dim], dim_y=K, hyperparams=hyperparams)\n",
    "\n",
    "train(hyperparams, estimator, x, y, net, DATASET)\n",
    "test(hyperparams, estimator, x_test, y_test, net, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
